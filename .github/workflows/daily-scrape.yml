name: Daily Scraping Job

on:
  schedule:
    # Run at 8:00 AM IST (2:30 UTC) every day
    - cron: '30 2 * * *'
  workflow_dispatch:  # Allows manual triggering for testing

jobs:
  scrape-and-create-sets:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Install MongoDB
        uses: supercharge/mongodb-github-action@v1.10.0
        with:
          mongodb-version: '4.4'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
      
      - name: Run automated scraper
        env:
          MYSQL_HOST: ${{ secrets.MYSQL_HOST }}
          MYSQL_USER: ${{ secrets.MYSQL_USER }}
          MYSQL_PASSWORD: ${{ secrets.MYSQL_PASSWORD }}
          MYSQL_DATABASE: ${{ secrets.MYSQL_DATABASE }}
          MYSQL_VERIFY_SSL: "false"
          MONGO_URI: ${{ secrets.MONGO_URI }}
          MAX_WORKER_THREADS: "4"
        run: python automated_scraper.py
